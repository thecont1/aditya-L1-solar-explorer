{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install sunpy astropy sherpa matplotlib -q\n",
    "\n",
    "from pathlib import Path\n",
    "import zipfile, gzip\n",
    "from io import BytesIO\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from IPython.display import Markdown\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "from astropy.time import Time\n",
    "\n",
    "# import sherpa\n",
    "\n",
    "# import sunpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the latest Aditya-L1 zip\n",
    "data_dir     = Path('data')\n",
    "source_files = sorted(data_dir.glob('AL1_SLX_L1_*_v1.0.zip'))\n",
    "if not source_files:\n",
    "    raise FileNotFoundError(\"No ZIP files found in data/\")\n",
    "print(\"Most recent data file:\", source_files[-1].name, end='\\n\\n')\n",
    "\n",
    "# Locate the SDD2 light-curve gz inside that zip\n",
    "with zipfile.ZipFile(source_files[-1], 'r') as z:\n",
    "    members = [m for m in z.namelist() if m.endswith('.lc.gz') and '/SDD2/' in m]\n",
    "    if not members:\n",
    "        raise FileNotFoundError(f\"No SDD2 .lc.gz found in {source_files[-1].name}\")\n",
    "\n",
    "    # Decompress & open with FITS\n",
    "    raw = z.read(members[0])\n",
    "    with gzip.GzipFile(fileobj=BytesIO(raw)) as dec:\n",
    "        hdul = fits.open(dec)\n",
    "        hdul.info()\n",
    "\n",
    "        # Render HDU0 header\n",
    "        hdr0 = hdul[0].header\n",
    "        df0 = pd.DataFrame({\n",
    "            \"Keyword\": list(hdr0.keys()),\n",
    "            \"Value\":   [hdr0[k] for k in hdr0.keys()],\n",
    "            \"Comment\": [hdr0.comments[k] for k in hdr0.keys()]\n",
    "        })\n",
    "        display(Markdown(\"### Primary HDU Header\\n\" + df0.to_markdown(index=False)))\n",
    "\n",
    "        # Render HDU1 (table) header\n",
    "        hdr1 = hdul[1].header\n",
    "        df1 = pd.DataFrame({\n",
    "            \"Keyword\": list(hdr1.keys()),\n",
    "            \"Value\":   [hdr1[k] for k in hdr1.keys()],\n",
    "            \"Comment\": [hdr1.comments[k] for k in hdr1.keys()]\n",
    "        })\n",
    "        display(Markdown(\"### Table HDU Header\\n\" + df1.to_markdown(index=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_file = Path('SoLEXS_dataset.parquet')\n",
    "if parquet_file.exists():\n",
    "\n",
    "    SoLEXS_df       = pd.read_parquet(parquet_file)\n",
    "    processed_dates = SoLEXS_df['DATE'].dt.strftime('%Y%m%d').unique()\n",
    "    for day in source_files.copy():\n",
    "        if day.stem.split('_')[3] in processed_dates:\n",
    "            source_files.remove(Path(day))\n",
    "\n",
    "else:\n",
    "    \n",
    "    SoLEXS_df       = pd.DataFrame()\n",
    "\n",
    "for zip_path in source_files:\n",
    "    prefix = f\"{zip_path.stem}/SDD2/\"\n",
    "    with zipfile.ZipFile(zip_path) as zf:\n",
    "        for member in zf.namelist():\n",
    "            if member.startswith(prefix) and member.endswith('.lc.gz'):\n",
    "                raw = zf.read(member)\n",
    "                with gzip.GzipFile(fileobj=BytesIO(raw)) as dec:\n",
    "                    tbl = Table.read(dec, format='fits')\n",
    "                    df  = tbl.to_pandas()\n",
    "                    df['DATE'] = pd.to_datetime(zip_path.stem.split('_')[3], format='%Y%m%d')\n",
    "                    df['TIME'] = df['TIME'].astype(int)\n",
    "                    SoLEXS_df = pd.concat([SoLEXS_df, df], ignore_index=True)\n",
    "\n",
    "SoLEXS_df   = SoLEXS_df[['DATE','TIME','COUNTS']]\n",
    "SoLEXS_df.to_parquet(parquet_file, index=False)\n",
    "print(f\"Appended {len(source_files)} new days; Total rows now {len(SoLEXS_df)}\")\n",
    "\n",
    "display(SoLEXS_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADITYA_EPOCH_UNIX = 1693612800  # 2023-09-02T00:00:00 UTC\n",
    "\n",
    "display(SoLEXS_df.describe().loc[['min', 'max'], ['DATE', 'TIME']])\n",
    "display(SoLEXS_df.describe().loc[:, ['COUNTS']].T.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2025-03-20'\n",
    "end_date   = '2025-03-27'\n",
    "\n",
    "df = SoLEXS_df[(SoLEXS_df['DATE'] >= start_date) & (SoLEXS_df['DATE'] <= end_date)].copy()\n",
    "display(df.describe().loc[['min', 'max']])\n",
    "\n",
    "gap = 60    # Seconds of inactivity to split events\n",
    "sigma = 5   # Threshold = median + sigma * std\n",
    "\n",
    "times = SoLEXS_df['TIME']\n",
    "counts = SoLEXS_df['COUNTS']\n",
    "\n",
    "# Return sorted unique unix times where counts exceed median + sigma*std.\n",
    "med, std = np.nanmedian(counts), np.nanstd(counts)\n",
    "mask = counts > (med + sigma*std)\n",
    "spikes = np.unique(times[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster unix timestamps into events: \n",
    "# gaps > `gap` seconds → new event.\n",
    "# Returns list of (t_start, t_end) tuples.\n",
    "if spikes.size == 0:\n",
    "    events = []\n",
    "else:\n",
    "    groups = [[spikes[0]]]\n",
    "    for t in spikes[1:]:\n",
    "        if t - groups[-1][-1] <= gap:\n",
    "            groups[-1].append(t)\n",
    "        else:\n",
    "            groups.append([t])\n",
    "    events = [(g[0], g[-1]) for g in groups]\n",
    "\n",
    "if not events:\n",
    "    print(\"No flares detected.\")\n",
    "else:\n",
    "    for i, ev in enumerate(events, 1):\n",
    "        t0, t1 = Time(ev[0], format='unix'), Time(ev[1], format='unix')\n",
    "        # midnight of that day:\n",
    "        mid = Time(t0.iso[:10]+'T00:00:00', format='isot', scale='utc')\n",
    "        info = {'start_iso': t0.iso,\n",
    "                'end_iso':   t1.iso,\n",
    "                'start_sod': (t0 - mid).sec,\n",
    "                'end_sod':   (t1 - mid).sec}\n",
    "        print(f\"Flare {i}: {info['start_iso']} → {info['end_iso']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = Time(df['TIME'].iloc[0], format='unix').to_datetime().strftime('%H:%M:%S')\n",
    "end_time = Time(df['TIME'].iloc[-1], format='unix').to_datetime().strftime('%H:%M:%S')\n",
    "\n",
    "plt_times = Time(df['TIME'], format='unix').to_datetime()\n",
    "plt.figure(figsize=(30, 15), dpi=300)\n",
    "plt.plot(plt_times, df['COUNTS'])\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%b %d %H:%M'))\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Time\", fontsize=16)\n",
    "plt.ylabel(\"X-Ray Count\", fontsize=16)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.title(f\"SoLEXS X-ray Lightcurve\\n\\n{start_date} {start_time} to {end_date} {end_time}\", fontsize=16, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = np.nanmedian(SoLEXS_df['COUNTS'])\n",
    "std_dev = np.nanstd(SoLEXS_df['COUNTS'])\n",
    "threshold = baseline + 5*std_dev\n",
    "\n",
    "times = df['TIME'].values\n",
    "# flare_indices = np.where(df['COUNTS'] > threshold)[0]\n",
    "flare_times = Time(np.unique(times), format='unix', scale='utc')\n",
    "t_ref = Time(times[0], format='unix', scale='utc')\n",
    "flare_offsets = (flare_times - t_ref).sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_idx = np.nanargmax(df['COUNTS'])\n",
    "window = 2400  # seconds around peak\n",
    "start = peak_idx - window\n",
    "end = peak_idx + window\n",
    "\n",
    "time_subset = Time(df['TIME'][start:end], format='unix').to_datetime()\n",
    "\n",
    "plt.figure(figsize=(30, 15), dpi=300)\n",
    "plt.plot(time_subset, df['COUNTS'][start:end])\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Time\", fontsize=16)\n",
    "plt.ylabel(\"X-Ray Count\", fontsize=16)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.title(f\"Zoomed-in Solar Flare\\n\\n{df['DATE'].iloc[-1].strftime('%Y-%m-%d')} {time_subset[0].strftime('%H:%M')} to {time_subset[-1].strftime('%H:%M')}\", fontsize=20, fontweight='bold')\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
