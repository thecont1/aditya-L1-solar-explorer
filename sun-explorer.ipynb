{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 🌞 0: Introduction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aditya-L1 is a solar observatory positioned 1.5 million kilometers from Earth at a place called the Lagrangian point L1, providing a continuous view of the Sun. \n",
    "\n",
    "SoLEXS is a spectrometer aboard Aditya-L1 that monitors X-ray emissions from the Sun, every second. This data is valuable for studying solar flares, which are bursts of energy released by the Sun.\n",
    "\n",
    "#### 🚀 `ADITYA_L1_EPOCH_UNIX` = 1693630800 \n",
    "#### 🚀 `ADITYA_L1_EPOCH_UTC` = 2023-09-02T06:20:00 UTC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 🌞 1: Set up the environment\n",
    "\n",
    "This cell imports necessary libraries for data handling, plotting, and interactive features. It sets up the environment for reading solar data and creating visualizations.\n",
    "\n",
    "1. `pandas` for data manipulation and analysis.\n",
    "\n",
    "2. `matplotlib.pyplot` for creating plots and figures.\n",
    "\n",
    "3. `astropy.io.fits` to read FITS-format files containing your lightcurve data.\n",
    "\n",
    "4. `astropy.time.Time` for converting Unix timestamps into human-readable dates/times.\n",
    "\n",
    "5. `gzip` and `zipfile` for handling compressed files.\n",
    "\n",
    "6. `tqdm` and `ipywidgets` for visualization and interactive widgets.\n",
    "\n",
    "7. `ipydatetime` for interactive date/time selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install astropy tqdm ipywidgets jupyter-ui-poll ipydatetime -q\n",
    "\n",
    "from pathlib import Path\n",
    "from io import BytesIO\n",
    "from tqdm.auto import tqdm\n",
    "import zipfile, gzip, io\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import Markdown, display, clear_output\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "from astropy.time import Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 🌞 2: Take a closer look at the `.lc` LightCurve file\n",
    "\n",
    "This cell demonstrates how to inspect a sample lightcurve file, showing its structure and header information to help understand the data format before processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most recent data file: AL1_SLX_L1_20250331_v1.0.zip\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "|   No. | Name    |   Ver | Type        |   Cards | Dimensions   | Format   |\n",
       "|------:|:--------|------:|:------------|--------:|:-------------|:---------|\n",
       "|     0 | PRIMARY |     1 | PrimaryHDU  |      15 |              |          |\n",
       "|     1 | RATE    |     1 | BinTableHDU |      39 | 86400R x 2C  | [D, D]   |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Primary HDU Header\n",
       "| Keyword   | Value                          | Comment                                        |\n",
       "|:----------|:-------------------------------|:-----------------------------------------------|\n",
       "| SIMPLE    | True                           | conforms to FITS standard                      |\n",
       "| BITPIX    | 8                              | array data type                                |\n",
       "| NAXIS     | 0                              | number of array dimensions                     |\n",
       "| EXTEND    | True                           |                                                |\n",
       "| MISSION   | ADITYA-L1                      | Name of mission/satellite                      |\n",
       "| TELESCOP  | AL1                            | Name of mission/satellite                      |\n",
       "| INSTRUME  | SoLEXS                         | Name of Instrument/detector                    |\n",
       "| ORIGIN    | SoLEXSPOC                      | Source of FITS file                            |\n",
       "| CREATOR   | solexs_pipeline-1.2            | Creator of file                                |\n",
       "| FILENAME  | AL1_SOLEXS_20250331_SDD2_L1.lc | Name of file                                   |\n",
       "| CONTENT   | LIGHT CURVE                    | File content                                   |\n",
       "| DATE      | 2025-04-08                     | Creation Date                                  |\n",
       "| OBS_DATE  | 20250331                       |                                                |\n",
       "| OBS_ID    | N00_0000_000474                |                                                |\n",
       "| DATASUM   | 0                              | data unit checksum updated 2025-04-08T17:24:36 |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Table HDU Header\n",
       "| Keyword   | Value                     | Comment                                         |\n",
       "|:----------|:--------------------------|:------------------------------------------------|\n",
       "| XTENSION  | BINTABLE                  | binary table extension                          |\n",
       "| BITPIX    | 8                         | array data type                                 |\n",
       "| NAXIS     | 2                         | number of array dimensions                      |\n",
       "| NAXIS1    | 16                        | length of dimension 1                           |\n",
       "| NAXIS2    | 86400                     | length of dimension 2                           |\n",
       "| PCOUNT    | 0                         | number of group parameters                      |\n",
       "| GCOUNT    | 1                         | number of groups                                |\n",
       "| TFIELDS   | 2                         | number of table fields                          |\n",
       "| EXTNAME   | RATE                      | Extension name                                  |\n",
       "| CONTENT   | LIGHT CURVE               | File content                                    |\n",
       "| HDUCLASS  | OGIP                      | format conforms to OGIP standard                |\n",
       "| HDUVERS   | 1.1.0                     | Version of format (OGIP memo CAL/GEN/92-002a)   |\n",
       "| HDUDOC    | OGIP memos CAL/GEN/92-007 | Documents describing the format                 |\n",
       "| HDUVERS1  | 1.0.0                     | Obsolete - included for backwards compatibility |\n",
       "| HDUVERS2  | 1.1.0                     | Obsolete - included for backwards compatibility |\n",
       "| HDUCLAS1  | LIGHTCURVE                | Extension contains spectral data                |\n",
       "| HDUCLAS2  | TOTAL                     |                                                 |\n",
       "| HDUCLAS3  | COUNTS                    |                                                 |\n",
       "| FILTER    | SDD2                      | Filter used                                     |\n",
       "| TTYPE1    | TIME                      |                                                 |\n",
       "| TFORM1    | D                         |                                                 |\n",
       "| TTYPE2    | COUNTS                    |                                                 |\n",
       "| TFORM2    | D                         |                                                 |\n",
       "| CREATOR   | solexs_pipeline-1.2       |                                                 |\n",
       "| TSTART    | 1743379200.0              |                                                 |\n",
       "| TSTOP     | 1743465599.0              |                                                 |\n",
       "| TIMEDEL   | 1                         |                                                 |\n",
       "| TIMZERO   | 0                         |                                                 |\n",
       "| MJDREFI   | 40587                     |                                                 |\n",
       "| MJDREFF   | 0                         |                                                 |\n",
       "| TIMESYS   | UTC                       |                                                 |\n",
       "| TIMEREF   | LOCAL                     |                                                 |\n",
       "| TIMEUNIT  | s                         |                                                 |\n",
       "| DATE-OBS  | 2025-03-31 00:00:00       |                                                 |\n",
       "| DATE-END  | 2025-03-31 23:59:59       |                                                 |\n",
       "| TELESCOP  | AL1                       |                                                 |\n",
       "| INSTRUME  | SoLEXS                    |                                                 |\n",
       "| NUMBAND   | 4                         |                                                 |\n",
       "| DATASUM   | 2065465298                | data unit checksum updated 2025-04-08T17:24:36  |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_dir = Path('data')\n",
    "zips     = sorted(data_dir.glob('AL1_SLX_L1_*_v1.0.zip'))\n",
    "if not zips:\n",
    "    raise FileNotFoundError(f\"No Aditya-L1 ZIPs in {data_dir}\")\n",
    "latest   = zips[-1]\n",
    "\n",
    "print(f\"Most recent data file: {latest.name}\")\n",
    "\n",
    "# Extract and open FITS in-memory\n",
    "with zipfile.ZipFile(latest, 'r') as z:\n",
    "    member = next(m for m in z.namelist() if '/SDD2/' in m and m.endswith('.lc.gz'))\n",
    "    raw    = z.read(member)\n",
    "\n",
    "with gzip.GzipFile(fileobj=io.BytesIO(raw)) as dec, fits.open(dec) as hdul:\n",
    "\n",
    "    # Build the “hdul.info()” table\n",
    "    info = []\n",
    "    for idx, hdu in enumerate(hdul):\n",
    "        hdr      = hdu.header\n",
    "        name     = hdr.get('EXTNAME', 'PRIMARY').strip()\n",
    "        ver      = hdr.get('EXTVER', 1)\n",
    "        hdu_type = type(hdu).__name__.replace('HDU','HDU')\n",
    "        cards    = len(hdr)\n",
    "        if hdu.data is not None:\n",
    "            nrows   = hdr.get('NAXIS2','')\n",
    "            nfields = hdr.get('TFIELDS','')\n",
    "            dims    = f\"{nrows}R x {nfields}C\"\n",
    "            tforms  = [hdr.get(f\"TFORM{i}\",'') for i in range(1, int(nfields)+1)]\n",
    "            fmt     = f\"[{', '.join(tforms)}]\"\n",
    "        else:\n",
    "            dims, fmt = '', ''\n",
    "        info.append({\n",
    "            \"No.\":        idx,\n",
    "            \"Name\":       name,\n",
    "            \"Ver\":        ver,\n",
    "            \"Type\":       hdu_type,\n",
    "            \"Cards\":      cards,\n",
    "            \"Dimensions\": dims,\n",
    "            \"Format\":     fmt\n",
    "        })\n",
    "\n",
    "    df_info = pd.DataFrame(info)\n",
    "    display(Markdown(df_info.to_markdown(index=False)))\n",
    "\n",
    "    # Render full headers for HDU0 & HDU1\n",
    "    for idx, title in ((0, \"Primary HDU\"), (1, \"Table HDU\")):\n",
    "        hdr = hdul[idx].header\n",
    "        df  = pd.DataFrame([\n",
    "            {\"Keyword\": k, \"Value\": hdr[k], \"Comment\": hdr.comments[k]}\n",
    "            for k in hdr.keys()\n",
    "        ])\n",
    "        display(Markdown(f\"## {title} Header\\n\" + df.to_markdown(index=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 🌞 3: Load the SoLEXS data\n",
    "\n",
    "This cell contains the `load_solexs_data` function, which reads and processes solar data from ZIP files, handles caching, and outputs a DataFrame for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 paths in SoLEXS_dataset.paths\n",
      "Found 26 ZIP files in data/archive/solexs_2025Apr19T040188866\n",
      "Found 46 ZIP files in data/archive/solexs_2025May14T043448388\n",
      "Found 56 ZIP files in data/archive/solexs_2025May14T044128344\n",
      "Found 58 ZIP files in data/archive/solexs_2025May14T044300021\n",
      "Found 60 ZIP files in data/archive/solexs_2025May14T044426758\n",
      "Processing 246 ZIP files from 5 paths\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e075b86fbc049deb69d71268ff229c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading FITS data:   0%|          | 0/246 [00:00<?, ? files/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built fresh dataset with 21,254,400 rows from 246 files\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>TIME</th>\n",
       "      <th>COUNTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>1719792000</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>1719792001</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>1719792002</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>1719792003</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>1719792004</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21254395</th>\n",
       "      <td>2025-03-31</td>\n",
       "      <td>1743465595</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21254396</th>\n",
       "      <td>2025-03-31</td>\n",
       "      <td>1743465596</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21254397</th>\n",
       "      <td>2025-03-31</td>\n",
       "      <td>1743465597</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21254398</th>\n",
       "      <td>2025-03-31</td>\n",
       "      <td>1743465598</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21254399</th>\n",
       "      <td>2025-03-31</td>\n",
       "      <td>1743465599</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21254400 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               DATE        TIME  COUNTS\n",
       "0        2024-07-01  1719792000      31\n",
       "1        2024-07-01  1719792001      34\n",
       "2        2024-07-01  1719792002      33\n",
       "3        2024-07-01  1719792003      42\n",
       "4        2024-07-01  1719792004      47\n",
       "...             ...         ...     ...\n",
       "21254395 2025-03-31  1743465595      75\n",
       "21254396 2025-03-31  1743465596      88\n",
       "21254397 2025-03-31  1743465597      78\n",
       "21254398 2025-03-31  1743465598      79\n",
       "21254399 2025-03-31  1743465599      86\n",
       "\n",
       "[21254400 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>1719792000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2025-03-31</td>\n",
       "      <td>1743465599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DATE        TIME\n",
       "min 2024-07-01  1719792000\n",
       "max 2025-03-31  1743465599"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>COUNTS</th>\n",
       "      <td>19674852</td>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>59</td>\n",
       "      <td>118</td>\n",
       "      <td>321993</td>\n",
       "      <td>551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count  mean  min  25%  50%  75%     max  std\n",
       "COUNTS  19674852   147    0   30   59  118  321993  551"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def load_solexs_data(paths_file='SoLEXS_dataset.paths',\n",
    "                     pattern='AL1_SLX_L1_*_v?.?.zip',\n",
    "                     out_parquet='SoLEXS_dataset.parquet') -> pd.DataFrame:\n",
    "    \"\"\"Load solar flare data from ZIP files at multiple paths and build a fresh Parquet dataset.\"\"\"\n",
    "    parquet_path = Path(out_parquet)\n",
    "    \n",
    "    # Read paths from the paths file\n",
    "    try:\n",
    "        with open(paths_file, 'r') as f:\n",
    "            data_paths = [line.strip() for line in f if line.strip()]\n",
    "        print(f\"Found {len(data_paths)} paths in {paths_file}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Paths file {paths_file} not found.\")\n",
    "        # If parquet exists, return it; otherwise return empty DataFrame\n",
    "        return pd.read_parquet(parquet_path) if parquet_path.exists() else pd.DataFrame()\n",
    "    \n",
    "    # Collect all ZIP files from all paths\n",
    "    all_zips = []\n",
    "    for path in data_paths:\n",
    "        path_obj = Path(path)\n",
    "        if not path_obj.exists():\n",
    "            print(f\"Warning: Path {path} does not exist, skipping\")\n",
    "            continue\n",
    "            \n",
    "        path_zips = sorted(path_obj.glob(pattern))\n",
    "        if path_zips:\n",
    "            print(f\"Found {len(path_zips)} ZIP files in {path}\")\n",
    "            all_zips.extend(path_zips)\n",
    "        else:\n",
    "            print(f\"No ZIP files matching '{pattern}' found in {path}\")\n",
    "    \n",
    "    # If no ZIPs found anywhere, return existing parquet if available\n",
    "    if not all_zips:\n",
    "        print(\"No data files found in any of the provided paths.\")\n",
    "        if parquet_path.exists():\n",
    "            print(f\"Using existing dataset from {out_parquet}\")\n",
    "            return pd.read_parquet(parquet_path)\n",
    "        else:\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "    print(f\"Processing {len(all_zips)} ZIP files from {len(data_paths)} paths\")\n",
    "    \n",
    "    # Process all ZIPs\n",
    "    all_dfs = []\n",
    "    for zp in tqdm(all_zips, desc='Loading FITS data', unit=' files'):\n",
    "        day = zp.stem.split('_')[3]\n",
    "        internal = f\"{zp.stem}/SDD2/AL1_SOLEXS_{day}_SDD2_L1.lc.gz\"\n",
    "\n",
    "        try:\n",
    "            with zipfile.ZipFile(zp) as zf:\n",
    "                try:\n",
    "                    raw = zf.read(internal)\n",
    "                except KeyError:\n",
    "                    print(f\"Warning: {internal} not found in {zp.name}, skipping\")\n",
    "                    continue\n",
    "                    \n",
    "            with gzip.GzipFile(fileobj=io.BytesIO(raw)) as dec:\n",
    "                table = Table.read(dec, format='fits')\n",
    "\n",
    "            df = table.to_pandas()\n",
    "            df['DATE'] = pd.to_datetime(day, format='%Y%m%d')\n",
    "            df['TIME'] = df['TIME'].astype(int)\n",
    "            df['COUNTS'] = df['COUNTS'].astype('Int64')\n",
    "            all_dfs.append(df[['DATE','TIME','COUNTS']])\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {zp.name}: {e}\")\n",
    "\n",
    "    # If we have data, build the dataset\n",
    "    if all_dfs:\n",
    "        # Combine all data frames\n",
    "        master = pd.concat(all_dfs, ignore_index=True)\n",
    "        \n",
    "        # Sort by DATE and TIME\n",
    "        master = master.sort_values(['DATE', 'TIME']).reset_index(drop=True)\n",
    "        \n",
    "        # Save to parquet, overwriting any existing file\n",
    "        master.to_parquet(out_parquet, index=False)\n",
    "        print(f\"Built fresh dataset with {len(master):,} rows from {len(all_dfs)} files\")\n",
    "        return master\n",
    "    else:\n",
    "        print(\"No data could be processed from the ZIP files.\")\n",
    "        # Return existing parquet if available\n",
    "        if parquet_path.exists():\n",
    "            print(f\"Using existing dataset from {out_parquet}\")\n",
    "            return pd.read_parquet(parquet_path)\n",
    "        else:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "# Load data, building a fresh dataset if data is available\n",
    "SoLEXS_df = load_solexs_data()\n",
    "\n",
    "# Only display info if we have data\n",
    "if not SoLEXS_df.empty:\n",
    "    display(SoLEXS_df)\n",
    "    display(SoLEXS_df.loc[:, ['DATE', 'TIME']].apply(['min', 'max'], axis=0))\n",
    "    display(SoLEXS_df.describe().loc[:, ['COUNTS']].T.astype(int))\n",
    "else:\n",
    "    print(\"No data available. Please check the paths in SoLEXS_dataset.paths\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 🌞 4: Setup interactive widgets and define plotting functions\n",
    "\n",
    "This cell creates interactive date/time selectors and parameters, allowing users to customize the analysis range and sensitivity for solar flare detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are default values that are loaded when the notebook initialises\n",
    "start_date = (SoLEXS_df['DATE'].max() - pd.Timedelta(days=15)).strftime('%Y-%m-%d')\n",
    "start_time = '00:00:00'\n",
    "\n",
    "end_date   = SoLEXS_df['DATE'].max().strftime('%Y-%m-%d')\n",
    "end_time   = '23:59:59'\n",
    "\n",
    "gap = 60*30    # Seconds of inactivity to split events\n",
    "sigma = 5   # Threshold = median + sigma * std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to use DatePicker widgets\n",
    "try:\n",
    "    # Create proper date picker widgets\n",
    "    date_widget = widgets.DatePicker(\n",
    "        description='Start date:',\n",
    "        value=pd.to_datetime(start_date).date()\n",
    "    )\n",
    "\n",
    "    end_date_widget = widgets.DatePicker(\n",
    "        description='End date:',\n",
    "        value=pd.to_datetime(end_date).date()\n",
    "    )\n",
    "except (ImportError, AttributeError, TypeError):\n",
    "    # Fall back to text widgets if DatePicker isn't available\n",
    "    date_widget = widgets.Text(\n",
    "        description='Start date:',\n",
    "        value=start_date,\n",
    "        placeholder='YYYY-MM-DD'\n",
    "    )\n",
    "\n",
    "    end_date_widget = widgets.Text(\n",
    "        description='End date:',\n",
    "        value=end_date,\n",
    "        placeholder='YYYY-MM-DD'\n",
    "    )\n",
    "\n",
    "# Time inputs (as text)\n",
    "start_time_widget = widgets.Text(\n",
    "    description='Start time:',\n",
    "    value=start_time,\n",
    "    placeholder='HH:MM:SS'\n",
    ")\n",
    "\n",
    "end_time_widget = widgets.Text(\n",
    "    description='End time:',\n",
    "    value=end_time,\n",
    "    placeholder='HH:MM:SS'\n",
    ")\n",
    "\n",
    "# Add descriptions for parameter widgets\n",
    "sigma_widget = widgets.IntSlider(\n",
    "    value=sigma,\n",
    "    min=1,\n",
    "    max=10,\n",
    "    step=1,\n",
    "    description='Sigma:',\n",
    "    tooltip='Threshold = median + sigma * std'\n",
    ")\n",
    "\n",
    "gap_widget = widgets.IntSlider(\n",
    "    value=gap,\n",
    "    min=60,\n",
    "    max=7200,\n",
    "    step=60,\n",
    "    description='Gap (sec):',\n",
    "    tooltip='Seconds of inactivity to split events'\n",
    ")\n",
    "\n",
    "# Add zoom window widget\n",
    "zoom_window = 20  # Default: 10 minutes\n",
    "zoom_widget = widgets.IntSlider(\n",
    "    value=zoom_window,\n",
    "    min=1,\n",
    "    max=60,\n",
    "    step=1,\n",
    "    description='Zoom (min):',\n",
    "    tooltip='Minutes to show around flare peak'\n",
    ")\n",
    "\n",
    "# Add a Run button\n",
    "run_button = widgets.Button(\n",
    "    description='Update Analysis',\n",
    "    button_style='success',\n",
    "    icon='play', \n",
    "    tooltip='Update parameters and data window',\n",
    "    layout=widgets.Layout(margin='20px')\n",
    ")\n",
    "\n",
    "# Stats output area\n",
    "stats_output = widgets.Output()\n",
    "\n",
    "# Layout with styling\n",
    "controls = widgets.VBox([\n",
    "    widgets.HTML(\"<h3>Solar Flare Analysis Parameters</h3>\"),\n",
    "    widgets.HBox([\n",
    "        widgets.VBox([date_widget, start_time_widget]),\n",
    "        widgets.VBox([end_date_widget, end_time_widget])\n",
    "    ]),\n",
    "    widgets.HBox([\n",
    "        widgets.VBox([sigma_widget]),\n",
    "        widgets.VBox([gap_widget])\n",
    "    ]),\n",
    "    widgets.VBox([zoom_widget]),\n",
    "    run_button,\n",
    "    stats_output  # Add stats output directly below controls\n",
    "])\n",
    "\n",
    "# Function to run analysis\n",
    "def run_analysis(b):\n",
    "    global df, times, counts, med, std, flares, zoom_window\n",
    "    \n",
    "    # Update global zoom_window from widget\n",
    "    zoom_window = zoom_widget.value\n",
    "    \n",
    "    # Get values from widgets\n",
    "    if hasattr(date_widget.value, 'strftime'):\n",
    "        start_date_val = date_widget.value.strftime('%Y-%m-%d')\n",
    "    else:\n",
    "        start_date_val = date_widget.value\n",
    "        \n",
    "    if hasattr(end_date_widget.value, 'strftime'):\n",
    "        end_date_val = end_date_widget.value.strftime('%Y-%m-%d')\n",
    "    else:\n",
    "        end_date_val = end_date_widget.value\n",
    "    \n",
    "    start_time_val = start_time_widget.value\n",
    "    end_time_val = end_time_widget.value\n",
    "    sigma_val = sigma_widget.value\n",
    "    gap_val = gap_widget.value\n",
    "    \n",
    "    # Clear previous output\n",
    "    with stats_output:\n",
    "        clear_output()\n",
    "        \n",
    "        # Show current parameters\n",
    "        print(f\"Analysis parameters:\\n\")\n",
    "        print(f\"Observation START: {start_date_val} {start_time_val}\")\n",
    "        print(f\"Observation  END : {end_date_val} {end_time_val}\")\n",
    "        print(f\"Sigma: {sigma_val} (flare detection threshold)\")\n",
    "        print(f\"Gap: {gap_val} seconds (between separate flares)\")\n",
    "        print(f\"Zoom window: {zoom_window} minutes (for flare detail view)\")\n",
    "        \n",
    "        # Filter by date range\n",
    "        df = SoLEXS_df[\n",
    "            (SoLEXS_df['DATE'] >= start_date_val) & \n",
    "            (SoLEXS_df['DATE'] <= end_date_val)\n",
    "        ].copy()\n",
    "        \n",
    "        # Convert time strings to seconds\n",
    "        h, m, s = map(int, start_time_val.split(':'))\n",
    "        start_index = h * 3600 + m * 60 + s\n",
    "        \n",
    "        h, m, s = map(int, end_time_val.split(':'))\n",
    "        end_index = len(df) - (86400 - h * 3600 + m * 60 + s)\n",
    "        \n",
    "        # Apply time filtering\n",
    "        df = df.iloc[start_index:end_index]\n",
    "        \n",
    "        if len(df) == 0:\n",
    "            print(\"\\nNo data available for the selected range.\")\n",
    "            return\n",
    "        \n",
    "        # Display data window\n",
    "        print(\"\\n\\nData Window:\")\n",
    "        display(df.loc[:, ['DATE', 'TIME']].apply(['min', 'max'], axis=0))\n",
    "        display(df.describe().loc[:, ['COUNTS']].T.astype(int))\n",
    "        \n",
    "        times = df['TIME']\n",
    "        counts = df['COUNTS']\n",
    "        \n",
    "        # Find flares\n",
    "        med, std = np.nanmedian(counts), np.nanstd(counts)\n",
    "        mask = counts > (med + sigma_val * std)\n",
    "        spikes = np.unique(times[mask])\n",
    "        \n",
    "        flares = []\n",
    "        if spikes.size == 0:\n",
    "            print(\"\\nNo flares detected.\")\n",
    "        else:\n",
    "            groups = [[spikes[0]]]\n",
    "            for t in spikes[1:]:\n",
    "                if t - groups[-1][-1] <= gap_val:\n",
    "                    groups[-1].append(t)\n",
    "                else:\n",
    "                    groups.append([t])\n",
    "            events = [(g[0], g[-1]) for g in groups]\n",
    "            print(f\"\\nDetected {len(events)} {'flares' if len(events) > 1 else 'flare'}:\\n\")\n",
    "            for i, ev in enumerate(events, 1):\n",
    "                t0, t1 = Time(ev[0], format='unix'), Time(ev[1], format='unix')\n",
    "                # midnight of that day:\n",
    "                mid = Time(t0.iso[:10]+'T00:00:00', format='isot', scale='utc')\n",
    "                info = {'start_iso': t0.iso[:-4],\n",
    "                        'end_iso':   t1.iso[:-4],\n",
    "                        'start_sod': (t0 - mid).sec,\n",
    "                        'end_sod':   (t1 - mid).sec}\n",
    "                flares.append(info)\n",
    "                print(f\"🔥 Flare {i}: {info['start_iso']} → {info['end_iso']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 🌞 5. Set control variables and go flare hunting\n",
    "\n",
    "- **Date and Time Selection**: Allows you to specify the start and end dates/times for the data subset. This focuses the analysis on a particular period, making it easier to examine specific solar events.\n",
    "\n",
    "- **Sigma (σ)**: A threshold for flare detection sensitivity. Higher values detect only stronger flares by requiring a larger deviation from the mean count rate, reducing false positives.\n",
    "\n",
    "- **Gap**: Defines the minimum time interval (in seconds) between detected flares. It prevents closely spaced fluctuations from being counted as separate flares, ensuring more accurate event identification.\n",
    "\n",
    "- **Zoom start and end**: Controls the range of the plot for detailed viewing. Set these to focus on a specific subset of the data timeline for in-depth analysis of individual flares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0b528d09cc545e2b9b3bc970acd1ba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>Solar Flare Analysis Parameters</h3>'), HBox(children=(VBox(children=(DatePicke…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Connect the button to the function\n",
    "run_button.on_click(run_analysis)\n",
    "\n",
    "# Display the combined widgets and stats\n",
    "display(controls)\n",
    "\n",
    "# Run analysis once to show initial results\n",
    "run_analysis(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 🌞 6: Plot light curves and detect solar flares\n",
    "\n",
    "This cell defines a function to plot light curves and detect solar flares based on user inputs, providing visual insights into the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f1796116b5348f1af1989d5ea59fe47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='info', description='Update', icon='refresh', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d30f8133286419eaf66adff0006745d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Light Curve Plot with Update Button\n",
    "plot_output = widgets.Output()\n",
    "update_plot_button = widgets.Button(\n",
    "    description='Update',\n",
    "    button_style='info',\n",
    "    icon='refresh'\n",
    ")\n",
    "\n",
    "def update_light_curve(b):\n",
    "    global df, times, counts, med, std, flares\n",
    "    \n",
    "    with plot_output:\n",
    "        clear_output()\n",
    "        \n",
    "        if 'df' not in globals() or len(df) == 0:\n",
    "            print(\"No data available to run the analysis.\")\n",
    "            return\n",
    "            \n",
    "        # Plot the results\n",
    "        plot_start_time = Time(times.iloc[0], format='unix').to_datetime().strftime('%H:%M:%S')\n",
    "        plot_end_time = Time(times.iloc[-1], format='unix').to_datetime().strftime('%H:%M:%S')\n",
    "        \n",
    "        plt_times = Time(times, format='unix').to_datetime()\n",
    "        plt.figure(figsize=(30, 18), dpi=300)\n",
    "        plt.plot(plt_times, counts)\n",
    "        \n",
    "        plt.axhline(med, color='green', linestyle='-', linewidth=2,\n",
    "                    label=f'Median: {med:.0f}')\n",
    "        plt.axhline(med + sigma_widget.value * std, color='red', linestyle='-', linewidth=2,\n",
    "                    label=f'{sigma_widget.value}σ Threshold: {med + sigma_widget.value * std:.0f}')\n",
    "        \n",
    "        # Annotate flares\n",
    "        if 'flares' in globals() and flares:\n",
    "            for i, flare in enumerate(flares, 1):\n",
    "                t0, t1 = pd.to_datetime(flare['start_iso']), pd.to_datetime(flare['end_iso'])\n",
    "                win = (plt_times >= t0) & (plt_times <= t1)\n",
    "                if not win.any():\n",
    "                    continue\n",
    "                \n",
    "                times_win = plt_times[win]\n",
    "                counts_win = counts.iloc[win.nonzero()[0]]\n",
    "                rel_idx = counts_win.values.argmax()\n",
    "                t_max = times_win[rel_idx]\n",
    "                y_max = counts_win.iloc[rel_idx]\n",
    "                \n",
    "                plt.scatter(t_max, y_max, color='magenta', s=60, zorder=5)\n",
    "                plt.annotate(\n",
    "                    f\"Peak {i}\\n{t_max:%H:%M:%S}\",\n",
    "                    xy=(t_max, y_max),\n",
    "                    xytext=(-40, 0),\n",
    "                    textcoords='offset points',\n",
    "                    ha='right',\n",
    "                    va='center',\n",
    "                    color='magenta',\n",
    "                    fontsize=12,\n",
    "                    arrowprops=dict(\n",
    "                        arrowstyle='-|>',\n",
    "                        color='magenta',\n",
    "                        lw=1\n",
    "                    )\n",
    "                )\n",
    "        \n",
    "        plt.legend(fontsize=14)\n",
    "        plt.gcf().autofmt_xdate()\n",
    "        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%b %d %H:%M'))\n",
    "        plt.grid(True)\n",
    "        plt.xlabel(\"Time\", fontsize=14)\n",
    "        plt.ylabel(\"X-Ray Count\", fontsize=14)\n",
    "        plt.xticks(fontsize=12)\n",
    "        plt.yticks(fontsize=12)\n",
    "        \n",
    "        # Get date values for title\n",
    "        if hasattr(date_widget.value, 'strftime'):\n",
    "            start_date_val = date_widget.value.strftime('%Y-%m-%d')\n",
    "        else:\n",
    "            start_date_val = date_widget.value\n",
    "            \n",
    "        if hasattr(end_date_widget.value, 'strftime'):\n",
    "            end_date_val = end_date_widget.value.strftime('%Y-%m-%d')\n",
    "        else:\n",
    "            end_date_val = end_date_widget.value\n",
    "            \n",
    "        plt.title(\n",
    "            f\"SoLEXS X-ray Lightcurve\\n\\n\"\n",
    "            f\"{start_date_val} {plot_start_time} to {end_date_val} {plot_end_time}\",\n",
    "            fontsize=16, fontweight='bold'\n",
    "        )\n",
    "        plt.show()\n",
    "\n",
    "update_plot_button.on_click(update_light_curve)\n",
    "\n",
    "display(update_plot_button)\n",
    "display(plot_output)\n",
    "\n",
    "# Run once to show initial plot\n",
    "update_light_curve(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🌞 7: Zoom into the wildest flare\n",
    "\n",
    "This cell zooms into the largest flare detected in the previous step, providing a detailed view of its characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dec58e2dab404af9a45ad0e1bee761ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='info', description='Update', icon='refresh', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98bfb31ede894f6e883672dd0635807f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Zoomed Flare Plot with Update Button\n",
    "zoom_output = widgets.Output()\n",
    "update_zoom_button = widgets.Button(\n",
    "    description='Update',\n",
    "    button_style='info',\n",
    "    icon='refresh'\n",
    ")\n",
    "\n",
    "def update_zoomed_view(b):\n",
    "    global df, times, counts, flares, zoom_window\n",
    "    \n",
    "    with zoom_output:\n",
    "        clear_output()\n",
    "        \n",
    "        if 'df' not in globals() or len(df) == 0:\n",
    "            print(\"No data available to run the analysis.\")\n",
    "            return\n",
    "            \n",
    "        if 'flares' not in globals() or not flares:\n",
    "            print(\"No flares detected in the current data range.\")\n",
    "            return\n",
    "        \n",
    "        # Find the strongest flare\n",
    "        peak_idx = np.nanargmax(df['COUNTS'])\n",
    "        \n",
    "        # Ensure indices are within bounds\n",
    "        start = max(0, peak_idx - zoom_window*30)\n",
    "        end = min(len(df), peak_idx + zoom_window*30)\n",
    "        \n",
    "        if end - start < 10:\n",
    "            print(\"Insufficient data for zoomed view.\")\n",
    "            return\n",
    "            \n",
    "        time_subset = Time(df['TIME'].iloc[start:end], format='unix').to_datetime()\n",
    "        \n",
    "        plt.figure(figsize=(30, 18), dpi=300)\n",
    "        plt.plot(time_subset, df['COUNTS'].iloc[start:end])\n",
    "        plt.grid(True)\n",
    "        plt.xlabel(\"Time\", fontsize=14)\n",
    "        plt.ylabel(\"X-Ray Count\", fontsize=14)\n",
    "        plt.xticks(fontsize=12)\n",
    "        plt.yticks(fontsize=12)\n",
    "        \n",
    "        date_str = df['DATE'].iloc[peak_idx].strftime('%Y-%m-%d')\n",
    "        start_str = time_subset[0].strftime('%H:%M')\n",
    "        end_str = time_subset[-1].strftime('%H:%M')\n",
    "        \n",
    "        plt.title(f\"Zoomed-in Solar Flare\\n\\n{date_str} {start_str} to {end_str}\", \n",
    "                  fontsize=16, fontweight='bold')\n",
    "        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
    "        plt.show()\n",
    "\n",
    "update_zoom_button.on_click(update_zoomed_view)\n",
    "\n",
    "display(update_zoom_button)\n",
    "display(zoom_output)\n",
    "\n",
    "# Run once to show initial zoomed view\n",
    "update_zoomed_view(None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
